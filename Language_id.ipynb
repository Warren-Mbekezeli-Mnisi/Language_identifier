{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Language_id.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-03snvCA2V8",
        "outputId": "8d61f2dd-6222-478d-b08e-6337ef52c2c9"
      },
      "source": [
        "pip install parfit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting parfit\n",
            "  Downloading parfit-0.220.tar.gz (5.4 kB)\n",
            "Requirement already satisfied: joblib in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from parfit) (0.14.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from parfit) (3.1.3)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from parfit) (1.18.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (2.4.6)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from sklearn->parfit) (0.23.2)\n",
            "Requirement already satisfied: six in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->parfit) (1.14.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->parfit) (45.2.0.post20200210)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->parfit) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mbeke\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->parfit) (2.1.0)\n",
            "Building wheels for collected packages: parfit, sklearn\n",
            "  Building wheel for parfit (setup.py): started\n",
            "  Building wheel for parfit (setup.py): finished with status 'done'\n",
            "  Created wheel for parfit: filename=parfit-0.220-py3-none-any.whl size=8662 sha256=d836642aae00457ee1858e7b2a5915a390cc3330032172ce7e2ffa847dfd5bce\n",
            "  Stored in directory: c:\\users\\mbeke\\appdata\\local\\pip\\cache\\wheels\\9a\\3b\\19\\64addee68f796a7e7108c2658a8765d600753bc728e7beb55e\n",
            "  Building wheel for sklearn (setup.py): started\n",
            "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1320 sha256=d8b759a133f3d087710879e334fc060fc5e8e4caab3348dcf00d1e1e8b0186c3\n",
            "  Stored in directory: c:\\users\\mbeke\\appdata\\local\\pip\\cache\\wheels\\46\\ef\\c3\\157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built parfit sklearn\n",
            "Installing collected packages: sklearn, parfit\n",
            "Successfully installed parfit-0.220 sklearn-0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFN1zbLAA2V_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import rcParams\n",
        "import os\n",
        "import re, string\n",
        "#import parfit.parfit as pf\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQj6MASA2V_"
      },
      "source": [
        "train_set = pd.read_csv('train_set.csv')\n",
        "test_set = pd.read_csv('test_set.csv')"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr4jdZzqA2V_",
        "outputId": "a46ede70-416e-4497-ec20-c1204d9da119"
      },
      "source": [
        "train_set.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['lang_id', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiRKFHuiA2V_",
        "outputId": "1c5bec3b-c4f6-40b4-f251-c9b60855e6e2"
      },
      "source": [
        "train_set['lang_id'].value_counts()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nso    3000\n",
              "eng    3000\n",
              "ven    3000\n",
              "afr    3000\n",
              "xho    3000\n",
              "tsn    3000\n",
              "tso    3000\n",
              "zul    3000\n",
              "nbl    3000\n",
              "sot    3000\n",
              "ssw    3000\n",
              "Name: lang_id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZxtgN-QA2WA",
        "outputId": "04e55929-6d23-47c3-a4fa-39a3abe86092"
      },
      "source": [
        "output = re.sub(r'\\d+', '', '123hello 456worldtša !')\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello worldtša !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e31njRuA2WA"
      },
      "source": [
        "def text_cleaner(text):\n",
        "    \n",
        "    # Conversion  to lowercase\n",
        "    text = text.lower()\n",
        "    # Removal of numbers \n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Removal of extra whitespace \n",
        "    text = re.sub(r'\\s\\s+', ' ', text)\n",
        "    # Removal of space in front/beginning \n",
        "    text = text.strip(' ')\n",
        "    \n",
        "    #  removal of punctuation\n",
        "    text = ''.join([ch for ch in text if ch not in string.punctuation])\n",
        "\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ljiyz35A2WA",
        "outputId": "6f9bd475-da16-45d7-aa2e-32360a32c95e"
      },
      "source": [
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dR8HLWARULG"
      },
      "source": [
        "mzansi = ['eastern','cape', 'free' , 'state','gauteng', 'kwaZulu','natal', 'limpopo', 'mpumalanga', 'north',\n",
        "          'west', 'northern' , 'western', 'port' 'elizabeth', 'bloemfontein', 'johannesburg', 'durban',\n",
        "          'polokwane', 'mbombela', 'klerksdorp', 'kimberley', 'town', 'johannesburg', 'pietersburg', 'nelspruit' ]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59j6xmp_TyBM"
      },
      "source": [
        "def remove_mzansi(text):\n",
        "    return  \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() not in mzansi)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKvF7AJfA2WA"
      },
      "source": [
        "def remove_english(text):\n",
        "    #words = set(nltk.corpus.words.words())\n",
        "    return  \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() not in words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9f2uHoHqA2WA",
        "outputId": "f250edf9-2831-4b8f-9b67-520a02f8a5a8"
      },
      "source": [
        "#  testing remove english\n",
        "remove_english('izolo yesterday namhlanje today')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'izolo namhlanje'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX-_jh8hrpoN"
      },
      "source": [
        "Removing South African Cities and provinces from the data did not improve model performance, neither did removing english words from the non-english languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gGnh8O2A2WA"
      },
      "source": [
        "train_set['text'] = train_set['text'].apply(text_cleaner)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzTbvthVARSR"
      },
      "source": [
        "#for index, row in train_set.iterrows():\n",
        "#  if row['lang_id'] != 'eng':\n",
        "#    train_set.iloc[index, 1] = remove_english(train_set.iloc[index, 1])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_a5_jumA2WA"
      },
      "source": [
        "#train_set['text'] = train_set.loc[train_set['lang_id'] != 'eng']['text'].apply(remove_english)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlSaxF_bCnB1",
        "outputId": "3da1a37c-ec40-4c76-bf75-8698df8deb72"
      },
      "source": [
        "train_set.iloc[12]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lang_id                                                  zul\n",
              "text       itipoffs anonymous wusizo locingo oluzimele fu...\n",
              "Name: 12, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBO7BIMYA2WA"
      },
      "source": [
        "X = train_set['text'].values\n",
        "y = train_set['lang_id'].values"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqxWzxZXA2WA"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
        "                                                  test_size=.01,\n",
        "                                                  random_state=42\n",
        "                                                  )"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZNwJstxA2WA"
      },
      "source": [
        "vectorizer = TfidfVectorizer(analyzer = 'char',\n",
        "                             ngram_range=(5, 5))\n",
        "\n",
        "pipe_naive = Pipeline([('vectorizer', vectorizer), ('naive_bayes', MultinomialNB(alpha = 0.5, fit_prior = True))])"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cxebzr7A2WA",
        "outputId": "c7a2df2a-aea7-4c53-f3e2-25c56551e5d0"
      },
      "source": [
        "pipe_naive.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'steps': [('vectorizer',\n",
              "   TfidfVectorizer(analyzer='char', ngram_range=(5, 5))),\n",
              "  ('naive_bayes', MultinomialNB())],\n",
              " 'verbose': False,\n",
              " 'vectorizer': TfidfVectorizer(analyzer='char', ngram_range=(5, 5)),\n",
              " 'naive_bayes': MultinomialNB(),\n",
              " 'vectorizer__analyzer': 'char',\n",
              " 'vectorizer__binary': False,\n",
              " 'vectorizer__decode_error': 'strict',\n",
              " 'vectorizer__dtype': numpy.float64,\n",
              " 'vectorizer__encoding': 'utf-8',\n",
              " 'vectorizer__input': 'content',\n",
              " 'vectorizer__lowercase': True,\n",
              " 'vectorizer__max_df': 1.0,\n",
              " 'vectorizer__max_features': None,\n",
              " 'vectorizer__min_df': 1,\n",
              " 'vectorizer__ngram_range': (5, 5),\n",
              " 'vectorizer__norm': 'l2',\n",
              " 'vectorizer__preprocessor': None,\n",
              " 'vectorizer__smooth_idf': True,\n",
              " 'vectorizer__stop_words': None,\n",
              " 'vectorizer__strip_accents': None,\n",
              " 'vectorizer__sublinear_tf': False,\n",
              " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              " 'vectorizer__tokenizer': None,\n",
              " 'vectorizer__use_idf': True,\n",
              " 'vectorizer__vocabulary': None,\n",
              " 'naive_bayes__alpha': 1.0,\n",
              " 'naive_bayes__class_prior': None,\n",
              " 'naive_bayes__fit_prior': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj3gmgs7A2WA",
        "outputId": "41a80b26-a81b-491b-eb68-04e801f30a29"
      },
      "source": [
        "grid_params = {\n",
        "  'vectorizer__max_df': np.linspace(0.5, 1.5, 6),\n",
        "  'vectorizer__binary': [True, False],\n",
        "}\n",
        "clf = GridSearchCV(pipe_naive , grid_params)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"Best Score: \", clf.best_score_)\n",
        "print(\"Best Params: \", clf.best_params_)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.9998163452708907\n",
            "Best Params:  {'vectorizer__binary': True, 'vectorizer__max_df': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me51E-0LA2WA",
        "outputId": "1ecee500-1b2c-4302-c208-75cb36f536ca"
      },
      "source": [
        "pipe_naive.fit(X_train, y_train)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vectorizer',\n",
              "                 TfidfVectorizer(analyzer='char', binary=True,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=0.5, max_features=None,\n",
              "                                 min_df=1, ngram_range=(5, 5), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('naive_bayes',\n",
              "                 MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPzeS4K-A2WB"
      },
      "source": [
        "y_pred = clf.predict(X_val)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Eha4iWA2WB",
        "outputId": "3e78c64e-53a1-450c-9e68-efdaf820acc5"
      },
      "source": [
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         afr       1.00      1.00      1.00        26\n",
            "         eng       1.00      1.00      1.00        36\n",
            "         nbl       1.00      1.00      1.00        25\n",
            "         nso       1.00      1.00      1.00        26\n",
            "         sot       1.00      1.00      1.00        31\n",
            "         ssw       1.00      1.00      1.00        25\n",
            "         tsn       1.00      1.00      1.00        35\n",
            "         tso       1.00      1.00      1.00        21\n",
            "         ven       1.00      1.00      1.00        28\n",
            "         xho       1.00      1.00      1.00        35\n",
            "         zul       1.00      1.00      1.00        42\n",
            "\n",
            "    accuracy                           1.00       330\n",
            "   macro avg       1.00      1.00      1.00       330\n",
            "weighted avg       1.00      1.00      1.00       330\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ogDj--cA2WB"
      },
      "source": [
        "test_set['text'] = test_set['text'].apply(text_cleaner)\n",
        "test_set['lang_id'] = clf.predict(test_set['text'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ADsgluZOA2WB",
        "outputId": "e7586f7f-d841-4b72-ad5c-27bef1e9a230"
      },
      "source": [
        "test_set.drop('text', axis = 1)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lang_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>tsn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>nbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>ssw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>afr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5677</th>\n",
              "      <td>5678</td>\n",
              "      <td>eng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5678</th>\n",
              "      <td>5679</td>\n",
              "      <td>nso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5679</th>\n",
              "      <td>5680</td>\n",
              "      <td>sot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5680</th>\n",
              "      <td>5681</td>\n",
              "      <td>sot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5681</th>\n",
              "      <td>5682</td>\n",
              "      <td>nbl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5682 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index lang_id\n",
              "0         1     tsn\n",
              "1         2     nbl\n",
              "2         3     ven\n",
              "3         4     ssw\n",
              "4         5     afr\n",
              "...     ...     ...\n",
              "5677   5678     eng\n",
              "5678   5679     nso\n",
              "5679   5680     sot\n",
              "5680   5681     sot\n",
              "5681   5682     nbl\n",
              "\n",
              "[5682 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHbmoV_A2WB"
      },
      "source": [
        "test_set[['index','lang_id']].to_csv('submission25.csv', index=False)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWZ3jAHDA2WB"
      },
      "source": [
        "submission = pd.read_csv('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-yBjn9fA2WB",
        "outputId": "cea54fed-753c-4de7-b70e-9194224b4b78"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lang_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>tsn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>nbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>ssw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>afr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index lang_id\n",
              "0      1     tsn\n",
              "1      2     nbl\n",
              "2      3     ven\n",
              "3      4     ssw\n",
              "4      5     afr"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iXa2SRHA2WB",
        "outputId": "53cb5a89-3ae3-4737-d3fd-6c0f535d88ce"
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lang_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xho</td>\n",
              "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xho</td>\n",
              "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eng</td>\n",
              "      <td>the province of kwazulu-natal department of tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nso</td>\n",
              "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ven</td>\n",
              "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  lang_id                                               text\n",
              "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
              "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
              "2     eng  the province of kwazulu-natal department of tr...\n",
              "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
              "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VCN9_0pA2WB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}